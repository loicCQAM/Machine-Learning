{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===spam.csv===\n",
      "\n",
      "ARBRE DE DÉCISION -----\n",
      "Correct classification rate for validation dataset (depth: 3) = 87.38574040219378%\n",
      "f1 score: 0.8726586755015376\n",
      "Correct classification rate for validation dataset (depth: 5) = 90.49360146252286%\n",
      "f1 score: 0.9047440679254657\n",
      "Correct classification rate for validation dataset (depth: 10) = 93.96709323583181%\n",
      "f1 score: 0.9396412162576825\n",
      "Correct classification rate for validation dataset (depth: None) = 95.24680073126143%\n",
      "f1 score: 0.9524680073126143\n",
      "\n",
      "BERNOULLI -------------\n",
      "Correct classification rate for the validation dataset = 90.12797074954297%\n",
      "f1 score: 0.9009758546794986\n",
      "BERNOULLI AVEC NORMALISATION\n",
      "Correct classification rate for the validation dataset = 90.12797074954297%\n",
      "f1 score: 0.9010803782302913\n",
      "\n",
      "KNN -------------------\n",
      "Correct classification rate for the validation dataset (neighbors: 3, weight: uniform) = 85.74040219378428%\n",
      "f1 score: 0.8579248135680351\n",
      "Correct classification rate for the validation dataset (neighbors: 3, weight: distance) = 90.31078610603291%\n",
      "f1 score: 0.9036581498849927\n",
      "Correct classification rate for the validation dataset (neighbors: 5, weight: uniform) = 81.90127970749543%\n",
      "f1 score: 0.819898144928025\n",
      "Correct classification rate for the validation dataset (neighbors: 5, weight: distance) = 90.49360146252286%\n",
      "f1 score: 0.9054388496866642\n",
      "Correct classification rate for the validation dataset (neighbors: 10, weight: uniform) = 78.61060329067642%\n",
      "f1 score: 0.7826279672753442\n",
      "Correct classification rate for the validation dataset (neighbors: 10, weight: distance) = 90.85923217550274%\n",
      "f1 score: 0.9090758170064078\n",
      "\n",
      "Decision Tree\n",
      "\n",
      "Correct classification rate with 10-fold (96.52173913043478%\n",
      "f1 score: 0.9652409877023712\n",
      "\n",
      "Bernoulli\n",
      "\n",
      "Correct classification rate with 10-fold (89.23913043478261%\n",
      "f1 score: 0.8915070045790451\n",
      "\n",
      "KNN\n",
      "\n",
      "Correct classification rate with 10-fold (93.07971014492755%\n",
      "f1 score: 0.9306416134254596\n",
      "\n",
      "===galaxy_feature_vectors.csv===\n",
      "\n",
      "ARBRE DE DÉCISION -----\n",
      "Correct classification rate for validation dataset (depth: 3) = 84.95073156166019%\n",
      "f1 score: 0.8491053716080083\n",
      "Correct classification rate for validation dataset (depth: 5) = 87.54852194684982%\n",
      "f1 score: 0.8753988331918486\n",
      "Correct classification rate for validation dataset (depth: 10) = 95.61063003881756%\n",
      "f1 score: 0.9560998165375045\n",
      "Correct classification rate for validation dataset (depth: None) = 96.68557778441325%\n",
      "f1 score: 0.9668529398767342\n",
      "\n",
      "BERNOULLI -------------\n",
      "Correct classification rate for the validation dataset = 70.17020005971932%\n",
      "f1 score: 0.6994905589961449\n",
      "BERNOULLI AVEC NORMALISATION\n",
      "Correct classification rate for the validation dataset = 55.53896685577785%\n",
      "f1 score: 0.5204124201402\n",
      "\n",
      "KNN -------------------\n",
      "Correct classification rate for the validation dataset (neighbors: 3, weight: uniform) = 77.18722006569125%\n",
      "f1 score: 0.7718099205719142\n",
      "Correct classification rate for the validation dataset (neighbors: 3, weight: distance) = 85.96595998805614%\n",
      "f1 score: 0.8595976076459914\n",
      "Correct classification rate for the validation dataset (neighbors: 5, weight: uniform) = 71.30486712451479%\n",
      "f1 score: 0.7128205123779863\n",
      "Correct classification rate for the validation dataset (neighbors: 5, weight: distance) = 85.84652134965661%\n",
      "f1 score: 0.8583782724389022\n",
      "Correct classification rate for the validation dataset (neighbors: 10, weight: uniform) = 66.91549716333233%\n",
      "f1 score: 0.6690610971615479\n",
      "Correct classification rate for the validation dataset (neighbors: 10, weight: distance) = 86.20483726485519%\n",
      "f1 score: 0.8619636326303224\n",
      "\n",
      "Decision Tree\n",
      "\n",
      "Correct classification rate with 10-fold (96.85947480482612%\n",
      "f1 score: 0.9685936679377587\n",
      "\n",
      "Bernoulli\n",
      "\n",
      "Correct classification rate with 10-fold (70.69434587177668%\n",
      "f1 score: 0.7054864776578348\n",
      "\n",
      "KNN\n",
      "\n",
      "Correct classification rate with 10-fold (86.49160160870593%\n",
      "f1 score: 0.8649230676485015\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import random\n",
    "\n",
    "for fichier in ['spam.csv', 'galaxy_feature_vectors.csv']:\n",
    "    print(f\"\\n==={fichier}===\\n\")\n",
    "    entries = np.loadtxt(fichier, delimiter = ',' ,)\n",
    "    nb_features = len(entries[1]) - 1\n",
    "    random.shuffle(entries,random.random)\n",
    "\n",
    "    X = entries[:,:-1]\n",
    "    Y = entries[:,nb_features]\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3)\n",
    "    X_test, X_validation, Y_test, Y_validation = train_test_split(X_test, Y_test, test_size = 0.66)    \n",
    "\n",
    "    # ARBRE DE DECISION\n",
    "    print(\"ARBRE DE DÉCISION -----\")\n",
    "    depths = [3 ,5 ,10]\n",
    "\n",
    "    for depth in depths :\n",
    "        model = tree.DecisionTreeClassifier(criterion = 'entropy', max_depth = depth)\n",
    "        model = model.fit(X_train, Y_train)\n",
    "\n",
    "        Y_valid_pred = model.predict(X_validation)\n",
    "        Y_test_pred = model.predict(X_test)\n",
    "\n",
    "        accuracy_test = accuracy_score(Y_validation, Y_valid_pred)\n",
    "        f1 = f1_score(Y_validation, Y_valid_pred, average='weighted')\n",
    "        print('Correct classification rate for validation dataset (depth: ' + str(depth) + ') = ' + str(accuracy_test * 100) + '%')\n",
    "        print('f1 score: %s' % f1)\n",
    "        \n",
    "    model = tree.DecisionTreeClassifier(criterion = 'entropy', max_depth = None)\n",
    "    model = model.fit(X_train, Y_train)\n",
    "\n",
    "    Y_valid_pred = model.predict(X_validation)\n",
    "    Y_test_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy_test = accuracy_score(Y_validation, Y_valid_pred)\n",
    "    f1 = f1_score(Y_validation, Y_valid_pred, average='weighted')\n",
    "    print('Correct classification rate for validation dataset (depth: None) = ' + str(accuracy_test * 100) + '%')\n",
    "    print('f1 score: %s' % f1)\n",
    "    \n",
    "    # BAYES NAÏF (BERNOULLI)\n",
    "    print(\"\")\n",
    "    print(\"BERNOULLI -------------\")\n",
    "    model = BernoulliNB(alpha = 1.0, binarize = 0.0, class_prior = None, fit_prior = True)\n",
    "    model = model.fit(X_train, Y_train)\n",
    "\n",
    "    Y_valid_pred = model.predict(X_validation)\n",
    "    Y_valid_pred_prob = model.predict_proba(X_validation)\n",
    "\n",
    "    acc_digits_data = accuracy_score(Y_validation, Y_valid_pred)\n",
    "    f1 = f1_score(Y_validation, Y_valid_pred, average='weighted')\n",
    "    print('Correct classification rate for the validation dataset = ' + str(acc_digits_data * 100) + '%')\n",
    "    print('f1 score: %s' % f1)\n",
    "    \n",
    "    print(\"BERNOULLI AVEC NORMALISATION\")\n",
    "    X_train_norm = MinMaxScaler().fit_transform(X_train)\n",
    "    X_valid_norm = MinMaxScaler().fit_transform(X_validation)\n",
    "    model = BernoulliNB(alpha = 1.0, binarize = 0.0, class_prior = None, fit_prior = True)\n",
    "    model = model.fit(X_train_norm, Y_train)\n",
    "    \n",
    "    Y_valid_pred = model.predict(X_valid_norm)\n",
    "\n",
    "    acc_digits_data = accuracy_score(Y_validation, Y_valid_pred)\n",
    "    f1 = f1_score(Y_validation, Y_valid_pred, average='weighted')\n",
    "    print('Correct classification rate for the validation dataset = ' + str(acc_digits_data * 100) + '%')\n",
    "    print('f1 score: %s' % f1)\n",
    "\n",
    "    # KNN\n",
    "    print(\"\")\n",
    "    print(\"KNN -------------------\")\n",
    "    n_neighbors = [3, 5, 10]\n",
    "    weights = ['uniform', 'distance']\n",
    "\n",
    "    for nn in n_neighbors:\n",
    "        for w in weights:\n",
    "            metric = 'euclidean'\n",
    "            algorithm = 'brute'\n",
    "\n",
    "            model = neighbors.KNeighborsClassifier(nn, weights = w, algorithm = algorithm, metric = metric )\n",
    "            model = model.fit(X_train, Y_train)\n",
    "\n",
    "            Y_valid_pred = model.predict(X_validation)\n",
    "\n",
    "            Y_valid_pred_prob = model.predict_proba(X_validation)\n",
    "\n",
    "            acc_digits_data = accuracy_score(Y_validation, Y_valid_pred)\n",
    "            f1 = f1_score(Y_validation, Y_valid_pred, average='weighted')\n",
    "            print('Correct classification rate for the validation dataset (neighbors: ' + str(nn) + ', weight: '+ str(w) +') = ' + str(acc_digits_data * 100) + '%')\n",
    "            print('f1 score: %s' % f1)\n",
    "        \n",
    "    # ==== 10-fold CV ====\n",
    "\n",
    "    # === Decision tree ===\n",
    "    print('\\nDecision Tree\\n')\n",
    "    model = tree.DecisionTreeClassifier(max_depth=None)\n",
    "    y_cv_pred = cross_val_predict(model, X, Y, cv=10)\n",
    "    acc = accuracy_score(Y, y_cv_pred)\n",
    "    f1 = f1_score(Y, y_cv_pred, average='weighted')\n",
    "    print(f'Correct classification rate with 10-fold ({str(acc * 100)}' + '%')\n",
    "    print('f1 score: %s' % f1)\n",
    "\n",
    "    # === Bernoulli ===\n",
    "    print('\\nBernoulli\\n')\n",
    "    model = BernoulliNB(alpha = 1.0, binarize = 0.0, class_prior = None, fit_prior = True)\n",
    "    y_cv_pred = cross_val_predict(model, X, Y, cv=10)\n",
    "    acc = accuracy_score(Y, y_cv_pred)\n",
    "    f1 = f1_score(Y, y_cv_pred, average='weighted')\n",
    "    print(f'Correct classification rate with 10-fold ({str(acc * 100)}' + '%')\n",
    "    print('f1 score: %s' % f1)\n",
    "\n",
    "    # === KNN ===\n",
    "    print('\\nKNN\\n')\n",
    "    model = neighbors.KNeighborsClassifier(3, weights = 'distance', algorithm = 'brute', metric = 'euclidean' )\n",
    "    y_cv_pred = cross_val_predict(model, X, Y, cv=10)\n",
    "    acc = accuracy_score(Y, y_cv_pred)\n",
    "    f1 = f1_score(Y, y_cv_pred, average='weighted')\n",
    "    print(f'Correct classification rate with 10-fold ({str(acc * 100)}' + '%')\n",
    "    print('f1 score: %s' % f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
